---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.16.1
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

# init


## imports

```{python}
import matplotlib.pyplot as plt
import pandas as pd
import warnings

from pyspark.sql import functions as F
from pyspark.sql import SparkSession
from pyspark.sql import types as T
from pyspark.sql import Window as W

warnings.filterwarnings('ignore')
```

## configs

```{python}
SPARK_THREADS = 16
SPARK_MEMORY = 16
SPARK_TIMEZONE = 'America/Vancouver'
```

```{python}
BASE_PATH = ('/home/shaghayegh/class/ad_click/data/')
USER_DATA_PATH = BASE_PATH + 'raw_data/user_profile.csv'
AD_CLICK_DATA_PATH = BASE_PATH + 'raw_data/raw_sample.csv'
AD_INFO_DATA_PATH = BASE_PATH + 'raw_data/ad_feature.csv'

MERGED_DATA_PATH = BASE_PATH + 'merged.parquet'
DATASET_PATH = BASE_PATH + 'dataset.parquet'
```

## spark instantiation

```{python}
spark = (
    SparkSession 
    .builder 
    .master('local[{}]'.format(SPARK_THREADS)) 
    .config('spark.driver.memory', '{}g'.format(SPARK_MEMORY)) 
    .config('spark.sql.session.timeZone', SPARK_TIMEZONE) 
    .getOrCreate()
)
```

## util

```{python}
def summerize_df(df):
    print(df.count())
    df.show(3)
```

# load data

```{python}
user_df = spark.read.csv(USER_DATA_PATH, header = True, inferSchema=True)
summerize_df(user_df)
```

```{python}
ad_info_df = spark.read.csv(AD_INFO_DATA_PATH, header = True, inferSchema=True)
summerize_df(ad_info_df)
```

```{python}
ad_click_df = spark.read.csv(AD_CLICK_DATA_PATH, header = True, inferSchema=True)
summerize_df(ad_click_df)
```

# join

```{python}
ad_click_df = ad_click_df.withColumnRenamed('user', 'userid')

ad_click_user_df = ad_click_df.join(user_df, on='userid')
merged_df = ad_click_user_df.join(ad_info_df, on='adgroup_id')

merged_df.write.partitionBy('age_level', 'final_gender_code').parquet(MERGED_DATA_PATH)
summerize_df(merged_df)
```

```{python}
merged_df = spark.read.parquet(MERGED_DATA_PATH).withColumn('time', F.from_unixtime('time_stamp'))
merged_df.persist()
summerize_df(merged_df)
```

# features preparation


## userid features

```{python}
def get_user_features(df):
    window = W.partitionBy('userid').orderBy('time').rowsBetween(W.unboundedPreceding,-1)
    
    return (
        df
        .withColumn('user_ad_count', F.count('clk').over(window))
        .withColumn('user_ad_clk_count', F.sum('clk').over(window))
    )
    
users_features_df = get_user_features(merged_df)
users_features_df.select('userid', 'time', 'user_ad_count', 'user_ad_clk_count').sort('userid', 'time').show(50)
```

## adgroup features

```{python}
def get_ad_features(df):
    window = W.partitionBy('adgroup_id').orderBy('time').rowsBetween(W.unboundedPreceding,-1)
    
    return (
        df
        .withColumn('adgroup_count', F.count('clk').over(window))
        .withColumn('adgroup_clk_count', F.sum('clk').over(window))
    )
    
ad_features_df = get_ad_features(users_features_df)
(
    ad_features_df
    .select('adgroup_id', 'time', 'adgroup_count', 'adgroup_clk_count')
    .sort('adgroup_id', 'time')
    .show(30)
)
```

## campaign features

```{python}
def get_campaign_features(df):
    window = W.partitionBy('campaign_id').orderBy('time').rowsBetween(W.unboundedPreceding,-1)
    
    return (
        df
        .withColumn('campaign_count', F.count('clk').over(window))
        .withColumn('campaign_clk_count', F.sum('clk').over(window))
    )
    
campaign_features_df = get_campaign_features(ad_features_df)
campaign_features_df.show()
```

## category features

```{python}
def get_category_features(df):
    window = W.partitionBy('cate_id').orderBy('time').rowsBetween(W.unboundedPreceding,-1)
    
    return (
        df
        .withColumn('cate_count', F.count('clk').over(window))
        .withColumn('cate_clk_count', F.sum('clk').over(window))
    )
    
category_features_df = get_category_features(campaign_features_df)
category_features_df.show()
```

## category & gender features

```{python}
def get_cat_gender_features(df):
    window = W.partitionBy('cate_id', 'final_gender_code').orderBy('time').rowsBetween(W.unboundedPreceding,-1)
    
    return (
        df
        .withColumn('cat_gender_ad_count', F.count('clk').over(window))
        .withColumn('cat_gender_ad_clk_count', F.sum('clk').over(window))
    )
    
cat_gender_features_df =  get_cat_gender_features(category_features_df)
cat_gender_features_df.show()
```

## category & age features

```{python}
def get_cat_age_features(df):
    window = W.partitionBy('cate_id', 'age_level').orderBy('time').rowsBetween(W.unboundedPreceding,-1)
    
    return (
        df
        .withColumn('cat_age_ad_count', F.count('clk').over(window))
        .withColumn('cat_age_ad_clk_count', F.sum('clk').over(window))
    )
    
cat_age_features_df =  get_cat_age_features(cat_gender_features_df)
cat_age_features_df.show()
```

## gender, age & ad features

```{python}
def get_gender_age_ad_features(df):
    window = (
        W.partitionBy('adgroup_id', 'age_level', 'final_gender_code')
        .orderBy('time')
        .rowsBetween(W.unboundedPreceding,-1)
    )
    return (
        df
        .withColumn('gender_age_ad_count', F.count('clk').over(window))
        .withColumn('gender_age_ad_clk_count', F.sum('clk').over(window))
    )
    
gender_age_ad_features_df =  get_gender_age_ad_features(cat_age_features_df)
gender_age_ad_features_df.show()
```

# save dataset

```{python}
gender_age_ad_features_df.write.parquet(DATASET_PATH)
```

```{python}

```
